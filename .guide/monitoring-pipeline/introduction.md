# The Monitoring Pipeline

The Monitoring pipeline monitors the performance of a hosted model and the quality of the data it receives. It runs a series of tests and generates several reports using the data captured by the model and a reference dataset.

![Monitoring pipeline](.guide/monitoring-pipeline/images/monitoring.png)

Before we can run the Monitoring pipeline, we need to [generate fake traffic](.guide/monitoring-pipeline/generating-fake-traffic.md) to the hosted model. The model will store the input data and the predictions it generates. We will then [generate ground truth labels](.guide/monitoring-pipeline/generating-fake-labels.md) for that data to evaluate the model's performance.

To run the Monitoring pipeline, you can use the following `just` recipe:

```shell
just monitor
```

If you don't want to use the recipe, you can execute the following command:

```shell
uv run pipelines/monitoring.py run
```

The pipeline will load the reference and production datasets and generate a series of reports to evaluate the quality of the data and the model's performance. By default, the pipeline uses the `backend.Local` implementation to load the production data from a SQLite database. You can change the [backend implementation](pipelines/inference/backend.py) by specifying a different implementation using the `--backend` property:

```shell
uv run pipelines/monitoring.py run --backend backend.Local
```

To provide configuration settings to a specific backend implementation, you can use the `--config` parameter to supply a JSON configuration file to the pipeline. The [`config/local.json`](config/local.json) file is an example configuration file for the [`backend.Local`](pipelines/inference/backend.py) backend. You can use this file as follows:

```shell
uv run pipelines/monitoring.py \
    --config config config/local.json run \
    --backend backend.Local
```

By default, the pipeline will load the latest 500 samples stored in the backend and use them to generate the reports. You can change the number of samples to load by using the `--limit` parameter when running the pipeline:

```shell
uv run pipelines/monitoring.py run --limit 1000
```

To display the supported parameters of the Monitoring pipeline, run the following command:

```shell
uv run pipelines/monitoring.py run --help
```

After the pipeline finishes running, you can visualize the generated reports using Metaflow's built-in viewer. Run the card server using the command below, and navigate to [localhost:8334](http://localhost:8334). Every time you run the Monitoring pipeline, the viewer will automatically update to show the every report generated by the pipeline:

```shell
uv run pipelines/monitoring.py card server --port 8334
```